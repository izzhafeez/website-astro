{
  "api-development": {
    "title": "API Dev",
    "importance": 7,
    "date": 2019,
    "proficiency": 8,
    "description": [
      {
        "title": "description",
        "text": "API development refers to the process of creating and implementing Application Programming Interfaces (APIs) that enable communication and data exchange between different software systems, allowing developers to expose functionalities, share data, and integrate applications in a standardised and efficient manner."
      },
      {
        "title": "background",
        "text": "Over the years, I've picked up quite a few backend frameworks. With them, I've built quite a number of projects, from geospatial, to music, to languages. Currently, all of them have been taken down from Heroku (due to the discontinuation of the free tier), but I am continuing to develop them for use on my local machine (as I do find them useful to me)."
      }
    ],
    "related": [
      "portfolio/language/go",
      "portfolio/language/java",
      "portfolio/language/javascript",
      "portfolio/language/python",
      "portfolio/language/ruby",
      "portfolio/language/rust",
      "portfolio/technology/django",
      "portfolio/technology/express-js",
      "portfolio/technology/flask",
      "portfolio/technology/node-js",
      "portfolio/technology/rocket-rs",
      "portfolio/technology/ruby-on-rails",
      "portfolio/technology/spring",
      "portfolio/coding/bus-routes-optimiser",
      "portfolio/coding/chords-search-engine",
      "portfolio/coding/meetup-maker",
      "portfolio/coding/note-together",
      "portfolio/experience/fullstack-intern",
      "portfolio/skill/frontend-development",
      "portfolio/skill/software-engineering",
      "portfolio/skill/web-development"
    ]
  },
  "artificial-intelligence": {
    "title": "Artificial Intelligence",
    "description": [
      {
        "title": "description",
        "text": "Artificial intelligence (AI) refers to the convergent fields of computer and data science focused on building machines with human intelligence to perform tasks that would previously have required a human being. For example, learning, reasoning, problem-solving, perception, language understanding and more."
      }
    ],
    "related": [
      "portfolio/course/generative-ai-introduction",
      "portfolio/course/generative-ai-prompt-engineering"
    ]
  },
  "business-intelligence": {
    "title": "Business Intelligence",
    "description": [
      {
        "title": "description",
        "text": "Business intelligence (BI) is a technology-driven process for analyzing data and delivering actionable information that helps executives, managers and workers make informed business decisions."
      }
    ],
    "related": []
  },
  "business-requirements": {
    "title": "Business Requirements",
    "description": [
      {
        "title": "description",
        "text": "Business requirements, also known as stakeholder requirements specifications, describe the characteristics of a proposed system from the viewpoint of the system's end user like a CONOPS. Products, systems, software, and processes are ways of how to deliver, satisfy, or meet business requirements."
      }
    ],
    "related": [
      "portfolio/course/foundations-of-business-intelligence"
    ]
  },
  "communication": {
    "title": "Communication",
    "description": [
      {
        "title": "description",
        "text": "Communication is commonly defined as the transmission of information. Its precise definition is disputed and there are disagreements about whether unintentional or failed transmissions are included and whether communication not only transmits meaning but also creates it."
      }
    ],
    "related": [
      "portfolio/course/dashboards-reports",
      "portfolio/course/foundations-of-data-science",
      "portfolio/course/go-beyond-the-numbers",
      "portfolio/course/regression-analysis",
      "portfolio/course/the-nuts-and-bolts-of-machine-learning",
      "portfolio/course/the-power-of-statistics"
    ]
  },
  "cross-functional": {
    "title": "Cross-Functional",
    "description": [
      {
        "title": "description",
        "text": "A cross-functional team, also known as a multidisciplinary team or interdisciplinary team, is a group of people with different functional expertise working toward a common goal. It may include people from finance, marketing, operations, and human resources departments."
      }
    ],
    "related": [
      "portfolio/course/foundations-of-business-intelligence"
    ]
  },
  "dashboarding": {
    "title": "Dashboarding",
    "description": [
      {
        "title": "description",
        "text": "In business computer information systems, a dashboard is a type of graphical user interface which often provides at-a-glance views of key performance indicators relevant to a particular objective or business process."
      }
    ],
    "related": [
      "portfolio/course/dashboards-reports"
    ]
  },
  "data-aggregation": {
    "title": "Data Aggregation",
    "description": [
      {
        "title": "description",
        "text": "Data aggregation is the compiling of information from databases with intent to prepare combined datasets for data processing."
      }
    ],
    "related": [
      "portfolio/course/analyze-data-to-answer-questions"
    ]
  },
  "data-analysis": {
    "title": "Data Analysis",
    "description": [
      {
        "title": "description",
        "text": "Data analysis is the process of inspecting, cleansing, transforming, and modeling data with the goal of discovering useful information, informing conclusions, and supporting decision-making."
      }
    ],
    "related": [
      "portfolio/course/analyze-data-to-answer-questions",
      "portfolio/course/ask-questions-to-make-data-driven-decisions",
      "portfolio/course/chat-gpt-advanced-data-analysis",
      "portfolio/course/data-analysis-with-r",
      "portfolio/course/foundations-data-data-everywhere",
      "portfolio/course/generative-ai-elevate",
      "portfolio/course/go-beyond-the-numbers",
      "portfolio/course/google-advanced-data-analytics-capstone",
      "portfolio/course/google-data-analytics-capstone",
      "portfolio/course/share-data-through-the-art-of-visualization"
    ]
  },
  "data-cleaning": {
    "title": "Data Cleaning",
    "importance": 6,
    "date": 2019,
    "proficiency": 9,
    "description": [
      {
        "title": "description",
        "text": "Data cleaning, also known as data cleansing or data scrubbing, refers to the process of identifying and correcting or removing errors, inconsistencies, and inaccuracies in datasets, ensuring data quality and reliability for analysis, decision-making, and other data-driven processes."
      },
      {
        "title": "background",
        "text": "With the help of inbuilt Python libraries like datetime and regex, as well as some of my own packages, I built comprehensive pipelines for processing complex data into usable formats. This included a lot of free-written text, so quite a bit of regex matching was needed to get the job done.\nI also developed several reusable scripts and libraries that facilitate future cleaning of datasets."
      }
    ],
    "related": [
      "portfolio/language/python",
      "portfolio/language/r",
      "portfolio/language/sql",
      "portfolio/technology/pandas",
      "portfolio/experience/data-analytics",
      "portfolio/experience/data-management",
      "portfolio/coding/dynamic-resource-optimiser",
      "portfolio/coding/geospatial-extraction",
      "portfolio/coding/malls-of-singapore",
      "portfolio/coding/sentence-searcher",
      "portfolio/coding/svg-converter",
      "portfolio/skill/data-management",
      "portfolio/skill/data-mining",
      "portfolio/skill/data-science",
      "portfolio/skill/web-scraping"
    ]
  },
  "data-collection": {
    "title": "Data Collection",
    "description": [
      {
        "title": "description",
        "text": "Data collection is the process of gathering and measuring information on variables of interest, in an established systematic fashion that enables one to answer stated research questions, test hypotheses, and evaluate outcomes."
      }
    ],
    "related": [
      "portfolio/course/prepare-data-for-exploration"
    ]
  },
  "data-engineering": {
    "title": "Data Engineering",
    "description": [
      {
        "title": "description",
        "text": "Data engineering refers to the building of systems to enable the collection and usage of data. This data is usually used to enable subsequent analysis and data science; which often involves machine learning. Making the data usable usually involves substantial compute and storage, as well as data processing."
      }
    ],
    "related": [
      "portfolio/course/data-engineering-with-rust"
    ]
  },
  "data-ethics": {
    "title": "Data Ethics",
    "description": [
      {
        "title": "description",
        "text": "Big data ethics also known as simply data ethics refers to systemizing, defending, and recommending concepts of right and wrong conduct in relation to data, in particular personal data."
      }
    ],
    "related": [
      "portfolio/course/prepare-data-for-exploration"
    ]
  },
  "data-generation": {
    "title": "Data Generation",
    "description": [
      {
        "title": "description",
        "text": "Data generation (DG) refers to creating or producing new data. This can be done through various means, such as collecting data from sources, conducting surveys, performing experiments, or generating data through algorithms and simulations."
      }
    ],
    "related": [
      "portfolio/course/generative-ai-elevate"
    ]
  },
  "data-integrity": {
    "title": "Data Integrity",
    "description": [
      {
        "title": "description",
        "text": "Data integrity is a concept and process that ensures the accuracy, completeness, consistency, and validity of an organization's data. By following the process, organizations not only ensure the integrity of the data but guarantee they have accurate and correct data in their database."
      }
    ],
    "related": [
      "portfolio/course/process-data-from-dirty-to-clean"
    ]
  },
  "data-management": {
    "title": "Data Management",
    "importance": 5,
    "date": 2021,
    "proficiency": 4,
    "description": [
      {
        "title": "description",
        "text": "Data Management refers to the process of organizing, storing, protecting, and analysing data throughout its lifecycle, ensuring its availability, accuracy, and usability to support business operations, decision-making, and compliance with regulatory requirements."
      },
      {
        "title": "background",
        "text": "During my time in <</portfolio/experience/data-management>>Enterprise Information Management</>, I was tasked with developing a Sharepoint portal to promote good data management practices within the organisation. As such, not only do I have to internalise the information, but I also have to phrase it in a way that others can easily understand."
      }
    ],
    "related": [
      "portfolio/language/sql",
      "portfolio/experience/data-management",
      "portfolio/technology/ssms",
      "portfolio/skill/data-cleaning",
      "portfolio/skill/data-management",
      "portfolio/skill/data-modeling",
      "portfolio/skill/data-science",
      "portfolio/skill/data-visualisation",
      "portfolio/skill/frontend-development",
      "portfolio/skill/operational-analysis"
    ]
  },
  "data-mining": {
    "title": "Data Mining",
    "importance": 7,
    "date": 2019,
    "proficiency": 8,
    "description": [
      {
        "title": "description",
        "text": "Data mining is the process of extracting valuable insights, patterns, and knowledge from large volumes of data, using various statistical and machine learning techniques, to discover hidden patterns, relationships, and trends that can be used for making informed business decisions and predictions."
      },
      {
        "title": "background",
        "text": "Data Mining perfectly describes my role in <</portfolio/experience/data-analytics>>NS</>, where I was often tasked to extract data to predict and describe outcomes using <</portfolio/skill/machine-learning>>machine learning</> processes. This mainly came in the form of the <</portfolio/coding/dynamic-resource-optimiser>>optimisation model</> that I operated, but I also applied this to my juniors' work, supervising them in the development of data science models for the Logistics Department."
      }
    ],
    "related": [
      "portfolio/language/python",
      "portfolio/technology/pandas",
      "portfolio/experience/data-analytics",
      "portfolio/skill/data-cleaning",
      "portfolio/skill/data-science",
      "portfolio/skill/web-scraping",
      "portfolio/coding/malls-of-singapore",
      "portfolio/coding/sentence-searcher",
      "portfolio/coding/spiderman-web-scraper"
    ]
  },
  "data-modeling": {
    "title": "Data Modeling",
    "importance": 5,
    "date": 2021,
    "proficiency": 6,
    "description": [
      {
        "title": "description",
        "text": "Data modeling is the process of creating a conceptual representation of data entities, relationships, and attributes, allowing for the design and organisation of data structures that accurately represent real-world scenarios and support efficient data management and analysis."
      },
      {
        "title": "background",
        "text": "Data Modeling was part of my duties in <</portfolio/experience/data-management>>Enterprise Information Management</>, where I used ER Studio to create data models.\nAfterwards, I took several courses on Data Modeling, including the one by Mongo University, which helped to deepen my understanding of how to design databases.\nFinally, I took the <</portfolio/module/cs2102>>CS2102 Database Systems</> module, where I learnt how to normalise and design databases to optimise for queries."
      }
    ],
    "related": [
      "portfolio/experience/data-management",
      "portfolio/technology/er-studio",
      "portfolio/technology/mongo-db",
      "portfolio/technology/postgresql",
      "portfolio/language/javascript",
      "portfolio/language/sql",
      "portfolio/module/cs2102",
      "portfolio/skill/data-management",
      "portfolio/skill/data-science",
      "portfolio/coding/halal-recommender",
      "portfolio/coding/meetup-maker",
      "portfolio/coding/notes-telegram-bot"
    ]
  },
  "data-science": {
    "title": "Data Science",
    "importance": 8,
    "date": 2019,
    "proficiency": 7,
    "description": [
      {
        "title": "description",
        "text": "Data Science is an interdisciplinary field that combines scientific methods, algorithms, and tools to extract insights and knowledge from structured and unstructured data, using techniques such as data analysis, machine learning, and statistical modeling, to solve complex problems, make predictions, and drive data-informed decision-making."
      },
      {
        "title": "background",
        "text": "My data science journey started when I entered my <</portfolio/experience/data-analytics>>National Service</>, where I was tasked with simple data-cleaning tasks. However, the complexity of my work rapidly increased when I was exposed to the <</portfolio/coding/dynamic-resource-optimiser>>DRO</> project, which was an analytics model used to optimise the placement of ambulances in Singapore. I operates and closely maintained the model, resolving issues on my own as much as possible. From there, I had to answer analytics queries from various departments using the findings from the model, either by using <</portfolio/skill/data-visualisation>>Data Visualisation</> software or simple report files.\nBesides work, however, my interests in Geography and Music took control. For geography, I made many packages and projects to assist in the data science process, which eventually led me to creating my <</portfolio/coding/mrt-paths-analysis>>MRT Puzzle</>, whose solutions were visualised on <</portfolio/technology/jupyter>>Jupyter</> Notebook.\nOn the other hand, thanks to my knowledge on <</portfolio/certificate/deep-learning-tensorflow>>Deep Learning from my IBM course</>, I also developed RNN models to predict music chords, although they don't work very well."
      }
    ],
    "related": [
      "portfolio/certificate/deep-learning-tensorflow",
      "portfolio/language/python",
      "portfolio/language/r",
      "portfolio/technology/excel",
      "portfolio/technology/pandas",
      "portfolio/technology/power-bi",
      "portfolio/technology/pytorch",
      "portfolio/technology/qgis",
      "portfolio/technology/tableau",
      "portfolio/technology/tensorflow",
      "portfolio/coding/dynamic-resource-optimiser",
      "portfolio/coding/malls-of-singapore",
      "portfolio/coding/mrt-paths-analysis",
      "portfolio/module/cs2102",
      "portfolio/module/cs2109s",
      "portfolio/skill/data-cleaning",
      "portfolio/skill/data-management",
      "portfolio/skill/data-mining",
      "portfolio/skill/data-modeling",
      "portfolio/skill/data-visualisation",
      "portfolio/skill/geospatial-analytics",
      "portfolio/skill/machine-learning",
      "portfolio/skill/operational-analysis",
      "portfolio/skill/web-scraping"
    ]
  },
  "data-structures": {
    "title": "Data Structures",
    "importance": 5,
    "date": 2017,
    "proficiency": 7,
    "description": [
      {
        "title": "description",
        "text": "Data structures refer to the way data is organized, stored, and managed in computer memory, providing efficient and optimised ways to access, manipulate, and store data, enabling effective data management and algorithmic problem-solving in various software applications."
      },
      {
        "title": "background",
        "text": "While I did have some prior experience in Linked Lists and Binary Search Trees, I did learn quite a lot of new data structures during my <</portfolio/module/cs2040s>>CS2040S Data Structures and Algorithms</> and <</portfolio/module/cs3230>>CS3230 Design and Analysis of Algorithms</> modules. Among them, I used the KDTree, AVLTree and Graph Structures to design my <</portfolio/coding/geospatial-management>>Geospatial Management Framework</>."
      }
    ],
    "related": [
      "portfolio/module/cs2040s",
      "portfolio/language/cpp",
      "portfolio/language/python",
      "portfolio/language/rust",
      "portfolio/coding/geospatial-management",
      "portfolio/coding/sz-matrix"
    ]
  },
  "data-transformation": {
    "title": "Data Transformation",
    "description": [
      {
        "title": "description",
        "text": "Data transformation is the process of converting, cleansing, and structuring data into a usable format that can be analyzed to support decision making processes, and to propel the growth of an organization. Data transformation is used when data needs to be converted to match that of the destination system."
      }
    ],
    "related": [
      "portfolio/course/the-path-to-insights"
    ]
  },
  "data-visualisation": {
    "title": "Data Visualisation",
    "importance": 7,
    "date": 2019,
    "proficiency": 7,
    "description": [
      {
        "title": "description",
        "text": "Data visualisation is the process of presenting data in a visual format, such as charts, graphs, and maps, to facilitate understanding, exploration, and communication of patterns, trends, and insights hidden within the data."
      },
      {
        "title": "background",
        "text": "There isn't any particular personal project that I fully applied data visualisation on.  However, I do have quite a bit of professional experience in this, with visualisation software such as <</portfolio/technology/tableau>>Tableau</>, <</portfolio/technology/power-bi>>PowerBI</>, <</portfolio/technology/qgis>>QGIS</> and Seaborn.\nDuring my time in the <</portfolio/experience/data-management>>Ministry of Manpower</> as well as <</portfolio/technology/data-analytics>>SCDF</>, I've done many ad-hoc dashboards (that I don't think I'm allowed to go into detail).\nI also participated in the Data Analytics Competition organized by the NUS Statistics and Data Science Society, where teams had to visualise Grab taxi data."
      }
    ],
    "related": [
      "portfolio/language/python",
      "portfolio/language/r",
      "portfolio/technology/excel",
      "portfolio/technology/pandas",
      "portfolio/technology/power-bi",
      "portfolio/technology/qgis",
      "portfolio/technology/tableau",
      "portfolio/skill/data-management",
      "portfolio/skill/data-science",
      "portfolio/skill/geospatial-analytics",
      "portfolio/skill/machine-learning",
      "portfolio/skill/operational-analysis",
      "portfolio/coding/dynamic-resource-optimiser",
      "portfolio/coding/mrt-paths-analysis"
    ]
  },
  "database-optimisation": {
    "title": "Database Optimisation",
    "description": [
      {
        "title": "description",
        "text": "Query optimization is a feature of many relational database management systems and other databases such as NoSQL and graph databases. The query optimizer attempts to determine the most efficient way to execute a given query by considering the possible query plans."
      }
    ],
    "related": [
      "portfolio/course/the-path-to-insights"
    ]
  },
  "decision-making": {
    "title": "Decision Making",
    "description": [
      {
        "title": "description",
        "text": "In psychology, decision-making is regarded as the cognitive process resulting in the selection of a belief or a course of action among several possible alternative options. It could be either rational or irrational."
      }
    ],
    "related": [
      "portfolio/course/ask-questions-to-make-data-driven-decisions"
    ]
  },
  "dev-ops": {
    "title": "DevOps",
    "description": [
      {
        "title": "description",
        "text": "DevOps is the combination of cultural philosophies, practices, and tools that increases an organization's ability to deliver applications and services at high velocity: evolving and improving products at a faster pace than organizations using traditional software development and infrastructure management processes."
      }
    ],
    "related": [
      "portfolio/course/rust-for-dev-ops"
    ]
  },
  "documentation": {
    "title": "Code Docs",
    "importance": 5,
    "date": 2020,
    "proficiency": 5,
    "description": [
      {
        "title": "description",
        "text": "Code documentation is the practice of creating descriptive and explanatory information about software code, including comments, annotations, and supplementary documents, to facilitate understanding, maintainability, and collaboration among developers, aiding in code comprehension, usage, and future updates or modifications."
      },
      {
        "title": "background",
        "text": "Apart from work, I'd say I've documented quite a lot during my <</portfolio/module/cs2103t>>CS2103T Software Engineering</> module. <<https://ay2223s2-cs2103t-w14-2.github.io/tp/DeveloperGuide.html>>Here is the documentation that my team did.</> In total, I contributed over 2,600 lines of code for documentation alone, so I think I'm familiar enough with documentation."
      }
    ],
    "related": [
      "portfolio/experience/fullstack-intern",
      "portfolio/technology/plant-uml",
      "portfolio/coding/edumate"
    ]
  },
  "executive-summaries": {
    "title": "Executive Summaries",
    "description": [
      {
        "title": "description",
        "text": "An executive summary provides an overview of the main points of a larger report. It is often written to share with individuals who may not have time to review the entire report. The reader should be able to make a decision based only on reading the executive summary."
      }
    ],
    "related": [
      "portfolio/course/google-advanced-data-analytics-capstone"
    ]
  },
  "exploratory-data-analysis": {
    "title": "Exploratory Data Analysis",
    "description": [
      {
        "title": "description",
        "text": "In statistics, exploratory data analysis is an approach of analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods."
      }
    ],
    "related": [
      "portfolio/course/go-beyond-the-numbers"
    ]
  },
  "extraction-transformation-loading": {
    "title": "Extraction Transformation Loading (ETL)",
    "description": [
      {
        "title": "description",
        "text": "Extract, transform, and load (ETL) is the process of combining data from multiple sources into a large, central repository called a data warehouse. ETL uses a set of business rules to clean and organize raw data and prepare it for storage, data analytics, and machine learning (ML)."
      }
    ],
    "related": [
      "portfolio/course/the-path-to-insights"
    ]
  },
  "frontend-development": {
    "title": "Frontend Dev",
    "importance": 8,
    "date": 2019,
    "proficiency": 8,
    "description": [
      {
        "title": "description",
        "text": "Frontend development involves creating the user interface and user experience of a website or application, utilising HTML, CSS, and JavaScript to design and implement the visual and interactive components that users interact with directly."
      },
      {
        "title": "background",
        "text": "I've done a lot of personal websites over the years. This is version 6 of my personal website, based entirely in <</portfolio/technology/react-js>>React</>. But before this, I have practiced quite a bit of UI/UX skills, incorporating design elements inspired by different sites out there.\nAs for personal projects, I've used many frameworks over the years. For example, I've used <</portfolio/technology/vue-js>>Vue</> to develop the <</portfolio/coding/note-together>>NoteTogether</> project, and I've used <</portfolio/technology/angular-js>>Angular</> and <</portfolio/technology/svelte-js>>Svelte</> for other projects as well. Then there's also <</portfolio/technology/bootstrap>>Bootstrap</>, which I heavily use to style the frontend.\nBesides that, for my internship, I created a web application using React that showcased the company's geospatial API, so I got to apply my frontend knowledge to a proper application. Also, I've designed an organisation-wide data governance portal during my time in the <</portfolio/experience/data-management>>Ministry of Manpower</>, which aimed at enforcing sound <</portfolio/skill/data-management>>data management</> principles. During my time in <</portfolio/experience/data-analytics>>National Service</>, I also assisted in the development of the department website."
      }
    ],
    "related": [
      "portfolio/technology/angular-js",
      "portfolio/technology/react-js",
      "portfolio/technology/svelte-js",
      "portfolio/technology/vue-js",
      "portfolio/language/css",
      "portfolio/language/html",
      "portfolio/language/javascript",
      "portfolio/experience/data-analytics",
      "portfolio/experience/data-management",
      "portfolio/experience/fullstack-intern",
      "portfolio/skill/api-development",
      "portfolio/skill/data-management",
      "portfolio/skill/web-development",
      "portfolio/coding/bus-routes-optimiser",
      "portfolio/coding/note-together",
      "portfolio/coding/website-react"
    ]
  },
  "game-development": {
    "title": "Game Dev",
    "importance": 3,
    "date": 2020,
    "proficiency": 3,
    "description": [
      {
        "title": "description",
        "text": "Game development encompasses the creation, design, and programming of interactive games, involving various disciplines such as graphics rendering, physics simulation, artificial intelligence, audio engineering, and user interface design to create immersive and entertaining gaming experiences."
      },
      {
        "title": "background",
        "text": "Besides following a couple of game development tutorials on YouTube, I don't think I've created anything substantial on my own. Probably my only proper experience comes when attending club sessions of the Games Development Group, where we worked on games together (though I don't think I did much)."
      }
    ],
    "related": [
      "portfolio/language/c-sharp",
      "portfolio/technology/unity",
      "portfolio/coding/malls-of-singapore"
    ]
  },
  "generative-ai": {
    "title": "Generative AI",
    "description": [
      {
        "title": "description",
        "text": "Generative AI is a type of artificial intelligence technology that can produce various types of content, including text, imagery, audio and synthetic data."
      }
    ],
    "related": [
      "portfolio/course/generative-ai-elevate",
      "portfolio/course/generative-ai-introduction",
      "portfolio/course/generative-ai-prompt-engineering",
      "portfolio/course/trustworthy-generative-ai"
    ]
  },
  "geospatial-analytics": {
    "title": "Geospatial Analytics",
    "importance": 10,
    "date": 2019,
    "proficiency": 10,
    "description": [
      {
        "title": "description",
        "text": "Geospatial analytics refers to the process of analysing and interpreting data that has a geographic or spatial component, allowing for the extraction of valuable insights, patterns, and relationships within spatially referenced data, enabling applications in fields such as urban planning, environmental monitoring, logistics, and location-based services."
      },
      {
        "title": "background",
        "text": "Due to my deep interest in geography, Geospatial Analytics is what I spend most of my coding time on. Be it malls, schools, buses, roads, MRT or others, a lot of my projects involve Singapore's urban geography in one way or another.\nA typical project would first include the data extraction process, which means either performing <</portfolio/skill/web-scraping>>Web Scraping</> or calling data from API. Next, using my <</portfolio/coding/geospatial-management>>Geospatial Management Framework</>, I process this data and perform <</portfolio/skill/data-cleaning>>Data Cleaning</>.\nI'd say Geospatial Analytics best describes my work during my <</portfolio/experience/data-analytics>>National Service</>. Be it predicting and optimising ambulance response times, to finding trends in fire alarm data, this skill was intensely practiced during my time there.\nBut I think I'm most proud of my <</portfolio/coding/malls-of-singapore>>Malls Card Game</>, which really was the culmination of all the geospatial skills I've picked up till then."
      }
    ],
    "related": [
      "portfolio/language/python",
      "portfolio/technology/excel",
      "portfolio/technology/pandas",
      "portfolio/technology/qgis",
      "portfolio/coding/bus-routes-optimiser",
      "portfolio/coding/dynamic-resource-optimiser",
      "portfolio/coding/geospatial-extraction",
      "portfolio/coding/geospatial-management",
      "portfolio/coding/halal-recommender",
      "portfolio/coding/malls-of-singapore",
      "portfolio/coding/meetup-maker",
      "portfolio/coding/mrt-paths-analysis",
      "portfolio/skill/data-science",
      "portfolio/skill/data-visualisation",
      "portfolio/skill/operational-analysis"
    ]
  },
  "hypothesis-testing": {
    "title": "Hypothesis Testing",
    "description": [
      {
        "title": "description",
        "text": "A statistical hypothesis test is a method of statistical inference used to decide whether the data at hand sufficiently support a particular hypothesis. More generally, hypothesis testing allows us to make probabilistic statements about population parameters."
      }
    ],
    "related": [
      "portfolio/course/the-power-of-statistics"
    ]
  },
  "large-language-models": {
    "title": "large-language-models",
    "description": [
      {
        "title": "description",
        "text": "A large language model is a language model notable for its ability to achieve general-purpose language understanding and generation. LLMs acquire these abilities by learning statistical relationships from text documents during a computationally intensive self-supervised and semi-supervised training process."
      }
    ],
    "related": [
      "portfolio/course/generative-ai-introduction",
      "portfolio/course/prompt-engineering-for-chat-gpt",
      "portfolio/course/rust-llmops"
    ]
  },
  "machine-learning": {
    "title": "Machine Learning",
    "importance": 6,
    "date": 2019,
    "proficiency": 5,
    "description": [
      {
        "title": "description",
        "text": "Machine Learning (ML) consists of letting algorithms discover 'patterns', namely recurring patterns, in data sets. This data can be numbers, words, images, statistics etc."
      },
      {
        "title": "background",
        "text": "Besides the ML course I took in university, I've had a few run ins with Machine Learning during my <</portfolio/experience/data-analytics>>Data Analytics</> role. As part of my duties, I created a couple of models to aid in operational analysis. I'm not sure what I can divulge from my time there, but it roughly revolved around the Ops and Logistics departments."
      }
    ],
    "related": [
      "portfolio/module/cs2109s",
      "portfolio/experience/data-analytics",
      "portfolio/language/python",
      "portfolio/language/r",
      "portfolio/technology/pandas",
      "portfolio/technology/pytorch",
      "portfolio/technology/tensorflow",
      "portfolio/skill/data-science",
      "portfolio/skill/data-visualisation",
      "portfolio/coding/malls-of-singapore"
    ]
  },
  "metadata": {
    "title": "Metadata",
    "description": [
      {
        "title": "description",
        "text": "Metadata (or metainformation) is 'data that provides information about other data', but not the content of the data itself, such as the text of a message or the image itself. There are many distinct types of metadata, including: Descriptive metadata \u2013 the descriptive information about a resource."
      }
    ],
    "related": [
      "portfolio/course/prepare-data-for-exploration"
    ]
  },
  "natural-language-processing": {
    "title": "Natural Language Processing",
    "description": [
      {
        "title": "description",
        "text": "Natural language processing (NLP) is a branch of artificial intelligence (AI) that enables computers to comprehend, generate, and manipulate human language. Natural language processing has the ability to interrogate the data with natural language text or voice."
      }
    ],
    "related": [
      "portfolio/course/generative-ai-introduction"
    ]
  },
  "object-oriented-programming": {
    "title": "Object-Oriented Programming",
    "description": [
      {
        "title": "description",
        "text": "Object-oriented programming is a programming paradigm based on the concept of objects, which can contain data and code: data in the form of fields, and code in the form of procedures. A common feature of objects is that methods are attached to them and can access and modify the object's data fields."
      }
    ],
    "related": [
      "portfolio/course/building-objects-in-c"
    ]
  },
  "operational-analysis": {
    "title": "Operational Analysis",
    "importance": 8,
    "date": 2019,
    "proficiency": 8,
    "description": [
      {
        "title": "description",
        "text": "Operational Analysis involves the systematic evaluation and optimisation of business operations, processes, and systems to identify inefficiencies, improve productivity, enhance performance, and streamline workflows, resulting in more effective and efficient operations and ultimately driving better business outcomes."
      },
      {
        "title": "background",
        "text": "Similarly to <</portfolio/skill/data-mining>>Data Mining</>, I was heavily involved in Operational Analysis during my time in <</portfolio/experience/data-analytics>>National Service</>. This included the visualisations I've done using <</portfolio/technology/qgis>>QGIS</>, <</portfolio/technology/tableau>>Tableau</> and <</portfolio/language/python>>Python</>. Mainly, senior officers from other departments would approach my supervisor for assistance (since we are the analytics branch). Then, my supervisor would explain to me the situation the department is in, and what needs to be accomplished through the data. Then, I would proceed with the analysis, finding as many useful trends as I can, before presenting the findings."
      }
    ],
    "related": [
      "portfolio/language/python",
      "portfolio/language/r",
      "portfolio/technology/excel",
      "portfolio/technology/pandas",
      "portfolio/technology/power-bi",
      "portfolio/technology/qgis",
      "portfolio/technology/tableau",
      "portfolio/experience/data-analytics",
      "portfolio/coding/dynamic-resource-optimiser",
      "portfolio/skill/data-management",
      "portfolio/skill/data-science",
      "portfolio/skill/data-visualisation",
      "portfolio/skill/geospatial-analytics"
    ]
  },
  "predictive-modeling": {
    "title": "Predictive Modeling",
    "description": [
      {
        "title": "description",
        "text": "Predictive modeling is a commonly used statistical technique to predict future behavior. Predictive modeling solutions are a form of data-mining technology that works by analyzing historical and current data and generating a model to help predict future outcomes."
      }
    ],
    "related": [
      "portfolio/course/regression-analysis",
      "portfolio/course/the-nuts-and-bolts-of-machine-learning"
    ]
  },
  "probability": {
    "title": "Probability",
    "description": [
      {
        "title": "description",
        "text": "Probability is the branch of mathematics concerning events and numerical descriptions of how likely they are to occur. The probability of an event is a number between 0 and 1; the larger the probability, the more likely an event is to occur."
      }
    ],
    "related": [
      "portfolio/course/the-power-of-statistics"
    ]
  },
  "problem-formulation": {
    "title": "Problem Formulation",
    "description": [
      {
        "title": "description",
        "text": "The process of defining the specific problem being addressed in, for example, an environmental risk assessment. It involves articulating a question and defining how it may be answered (e.g. by identifying the endpoints to be measured)."
      }
    ],
    "related": [
      "portfolio/course/trustworthy-generative-ai"
    ]
  },
  "problem-solving": {
    "title": "Problem Solving",
    "importance": 6,
    "date": 2017,
    "proficiency": 7,
    "description": [
      {
        "title": "description",
        "text": "Problem-solving is the process of identifying, analysing, and resolving challenges or issues by employing critical thinking, logical reasoning, creativity, and decision-making skills, aiming to find effective solutions and overcome obstacles in various domains and contexts."
      },
      {
        "title": "background",
        "text": "There's no particular instance that comes to mind when talking about problem solving skills. Rather, I think it is just the way people approach problems that matters. I don't think I'm close to the best at solving such problems, but I think I'm ok."
      }
    ],
    "related": [
      "portfolio/experience/data-analytics"
    ]
  },
  "project-management": {
    "title": "Project Management",
    "description": [
      {
        "title": "description",
        "text": "Project management involves the planning and organization of a company's resources to move a specific task, event, or duty toward completion. It can involve a one-time project or an ongoing activity, and resources managed include personnel, finances, technology, and intellectual property."
      }
    ],
    "related": [
      "portfolio/course/foundations-of-data-science"
    ]
  },
  "prompt-engineering": {
    "title": "Prompt Engineering",
    "description": [
      {
        "title": "description",
        "text": "Prompt engineering is the process of structuring text that can be interpreted and understood by a generative AI model.[1][2] A prompt is natural language text describing the task that an AI should perform."
      }
    ],
    "related": [
      "portfolio/course/chat-gpt-advanced-data-analysis",
      "portfolio/course/generative-ai-prompt-engineering",
      "portfolio/course/prompt-engineering-for-chat-gpt",
      "portfolio/course/trustworthy-generative-ai"
    ]
  },
  "regression-analysis": {
    "title": "Regression Analysis",
    "description": [
      {
        "title": "description",
        "text": "Regression analysis is a reliable method of identifying which variables have impact on a topic of interest. The process of performing a regression allows you to confidently determine which factors matter most, which factors can be ignored, and how these factors influence each other."
      }
    ],
    "related": [
      "portfolio/course/regression-analysis"
    ]
  },
  "reporting": {
    "title": "Reporting",
    "description": [
      {
        "title": "description",
        "text": "Data reporting is the process of collecting and formatting raw data and translating it into a digestible format to assess the ongoing performance of your organization. Your data reports can answer basic questions about the state of your business."
      }
    ],
    "related": [
      "portfolio/course/dashboards-reports"
    ]
  },
  "sharing-insights": {
    "title": "Sharing Insights",
    "description": [
      {
        "title": "description",
        "text": "Data insights are found through the deep analysis of patterns and statistics within data. Through the interpretation of these patterns, organizations transform insights into forecasting customer needs, therefore promoting more effective decision-making."
      }
    ],
    "related": [
      "portfolio/course/dashboards-reports",
      "portfolio/course/foundations-of-business-intelligence",
      "portfolio/course/foundations-of-data-science"
    ]
  },
  "software-engineering": {
    "title": "Software Engineering",
    "importance": 8,
    "date": 2019,
    "proficiency": 7,
    "description": [
      {
        "title": "description",
        "text": "Software Engineering is the branch of computer science that deals with the design, development, testing and maintenance of software applications."
      },
      {
        "title": "background",
        "text": "If we're walking about pure desktop applications, I think my most fruitful contribution was during my <</portfolio/module/cs2103t>>CS2103T Software Engineering</> module. The projects were built using <</portfolio/language/java>>Java</>, and we had to extend an existing application (Address Book 3). Due to my over-zealousness during that semester, I ended up contributing 18,000+ lines of code to the codebase. As such, I think I have enough Software Engineering experience for now, or at least in Java.\nBesides that, I've done some software development on <</portfolio/language/rust>>Rust</>, where I made modifications to the <</portfolio/coding/neothesia>>Neothesia</> project, which I adapted to suit my needs."
      }
    ],
    "related": [
      "portfolio/module/cs2103t",
      "portfolio/module/cs3216",
      "portfolio/language/java",
      "portfolio/language/python",
      "portfolio/language/rust",
      "portfolio/technology/intellij",
      "portfolio/technology/junit",
      "portfolio/technology/vscode",
      "portfolio/skill/api-development",
      "portfolio/skill/software-testing",
      "portfolio/coding/dynamic-resource-optimiser",
      "portfolio/coding/edumate"
    ]
  },
  "software-testing": {
    "title": "Software Testing",
    "importance": 6,
    "date": 2019,
    "proficiency": 7,
    "description": [
      {
        "title": "description",
        "text": "Software testing is the process of evaluating a software system or application to ensure that it meets specified requirements, functions correctly, and performs as expected, using various techniques and tools to detect defects, verify functionality, and validate the quality and reliability of the software."
      },
      {
        "title": "background",
        "text": "Software Testing is done to validate and verify the behaviour of software; I applied it in three distinct instances. The most important of them would be the <</portfolio/coding/note-together>>NoteTogether</> project, where I did most of the background testing. Other instances would be this website, where I tested whether each subsite works properly (including the notes page).\n1. **Unit Testing**: I used the Postman API to test the API endpoints of NoteTogether, where variables such as verification token and note IDs are stored as environment variables. I set up over 50 unit test cases, which test different aspects of each API (error handling etc.)\n2. **Integration Testing**: I used Postman Flows to test the integration of different API endpoints of NoteTogether, creating complex networks of logic flow to simulate an actual interaction.\n3. **System Testing**: For more thorough testing of NoteTogether's backend design, I used Python to send requests to the server, and verify that all the data is updated accordingly.\n4. **Regression Testing**: For NoteTogether, the regression testing was done using GitHub Actions, using Python to run some scripts that test the behaviour of the app.\n5. **Continuous Integration / Continuous Deployment**: For NoteTogether, most of the CI/CD was done by my partner so my main experience in this area would be in the deployment of this personal site, where the build command is run in GitHub Actions.\n6. **Frontend Testing**: I like web scraping, so for NoteTogether, I was responsible for the frontend testing as well. Using Selenium on Python, I created scripts that mimicked the behaviour of the end user and tested whether the front responded accordingly.\n7. **Load Testing**: Using Python requests again, I tested the behaviour of our application at different loads, and made a regression curve approximating its performance as load increases.\n8. **Stress Testing**: Using Python requests again, I tested the ability of the application to handle high amounts of traffic. In particular, whether a large number of requests coming in would lead to a mismatch in fields."
      }
    ],
    "related": [
      "portfolio/module/cp2106",
      "portfolio/module/cs2103t",
      "portfolio/language/java",
      "portfolio/language/javascript",
      "portfolio/language/python",
      "portfolio/language/ruby",
      "portfolio/technology/jest",
      "portfolio/technology/junit",
      "portfolio/technology/postman",
      "portfolio/technology/selenium",
      "portfolio/experience/fullstack-intern",
      "portfolio/coding/bus-routes-optimiser",
      "portfolio/coding/edumate",
      "portfolio/coding/note-together",
      "portfolio/skill/software-engineering",
      "portfolio/skill/web-development"
    ]
  },
  "statistical-analysis": {
    "title": "Statistical Analysis",
    "description": [
      {
        "title": "description",
        "text": "Statistical analysis is the collection and interpretation of data in order to uncover patterns and trends. It is a component of data analytics. Statistical analysis can be used in situations like gathering research interpretations, statistical modeling or designing surveys and studies."
      }
    ],
    "related": [
      "portfolio/course/regression-analysis",
      "portfolio/course/the-power-of-statistics"
    ]
  },
  "system-programming": {
    "title": "System Programming",
    "description": [
      {
        "title": "description",
        "text": "Systems programming, or system programming, is the activity of programming computer system software."
      }
    ],
    "related": [
      "portfolio/course/data-engineering-with-rust",
      "portfolio/course/python-rust-linux",
      "portfolio/course/rust-for-dev-ops",
      "portfolio/course/rust-fundamentals"
    ]
  },
  "team-dynamics": {
    "title": "Team Dynamics",
    "description": [
      {
        "title": "description",
        "text": "Team dynamics refers to the relationships and interactions between team members that can affect their productivity and performance. It encompasses how team members communicate, collaborate, and coordinate their efforts to achieve a shared goal."
      }
    ],
    "related": [
      "portfolio/course/foundations-of-data-science"
    ]
  },
  "usability-testing": {
    "title": "Usability Testing",
    "description": [
      {
        "title": "description",
        "text": "Usability testing is a technique used in user-centered interaction design to evaluate a product by testing it on users. This can be seen as an irreplaceable usability practice, since it gives direct input on how real users use the system."
      }
    ],
    "related": [
      "portfolio/course/dynamic-user-interfaces",
      "portfolio/course/ux-for-social-good",
      "portfolio/course/ux-research"
    ]
  },
  "user-experience": {
    "title": "User Experience",
    "description": [
      {
        "title": "description",
        "text": "The user experience is how a user interacts with and experiences a product, system or service. It includes a person's perceptions of utility, ease of use, and efficiency."
      }
    ],
    "related": [
      "portfolio/course/dynamic-user-interfaces",
      "portfolio/course/empathize-define-ideate",
      "portfolio/course/foundations-of-ux",
      "portfolio/course/high-fidelity-designs-in-figma",
      "portfolio/course/ux-for-social-good",
      "portfolio/course/ux-research",
      "portfolio/course/wireframes-low-fidelity-prototypes"
    ]
  },
  "ux-design": {
    "title": "User Experience (UX) Design",
    "importance": 8,
    "date": 2023,
    "proficiency": 8,
    "description": [
      {
        "title": "description",
        "text": "UX Design is the process of creating products or services that provide meaningful experiences for users, involving many different areas of product development including branding, usability, function, and design."
      },
      {
        "title": "background",
        "text": "I think I went through enough hell with the design iteration process. From my experience in Assignment 1 and Final Project in CS3216, I learnt how to design a user-centric application, and how to conduct interviews for research and testing. I think the Google UX Design course gave me more clarity as to the specific reasons why certain things work and why some others don't."
      }
    ],
    "related": [
      "portfolio/certificate/google-ux-design",
      "portfolio/technology/figma"
    ]
  },
  "ux-research": {
    "title": "UX Research",
    "description": [
      {
        "title": "description",
        "text": "User experience (UX) research is about diving deep into how customers interact with your brand on a practical, functional level, and observing how easily they can complete their tasks and meet their goals."
      }
    ],
    "related": [
      "portfolio/course/empathize-define-ideate",
      "portfolio/course/foundations-of-ux",
      "portfolio/course/ux-research",
      "portfolio/course/wireframes-low-fidelity-prototypes"
    ]
  },
  "web-development": {
    "title": "Web Dev",
    "importance": 9,
    "date": 2019,
    "proficiency": 9,
    "description": [
      {
        "title": "description",
        "text": "Web development refers to the process of creating and building websites and web applications, involving the design, development, and implementation of web technologies such as HTML, CSS, JavaScript, and backend programming languages, to create interactive and functional websites that can be accessed and used over the internet."
      },
      {
        "title": "background",
        "text": "I think my commitment towards Web Development is best shown through the many projects I've built over the years. Do check them out, as they are made using different technologies."
      }
    ],
    "related": [
      "portfolio/skill/api-development",
      "portfolio/skill/frontend-development",
      "portfolio/skill/software-testing",
      "portfolio/language/css",
      "portfolio/language/go",
      "portfolio/language/html",
      "portfolio/language/java",
      "portfolio/language/javascript",
      "portfolio/language/php",
      "portfolio/language/python",
      "portfolio/language/rust",
      "portfolio/language/typescript",
      "portfolio/technology/angular-js",
      "portfolio/technology/bootstrap",
      "portfolio/technology/django",
      "portfolio/technology/express-js",
      "portfolio/technology/flask",
      "portfolio/technology/gcp",
      "portfolio/technology/heroku",
      "portfolio/technology/junit",
      "portfolio/technology/mongo-db",
      "portfolio/technology/node-js",
      "portfolio/technology/postgresql",
      "portfolio/technology/postman",
      "portfolio/technology/react-js",
      "portfolio/technology/rocket-rs",
      "portfolio/technology/ruby-on-rails",
      "portfolio/technology/selenium",
      "portfolio/technology/spring",
      "portfolio/technology/svelte-js",
      "portfolio/technology/vue-js",
      "portfolio/experience/data-analytics",
      "portfolio/experience/fullstack-intern",
      "portfolio/coding/bus-routes-optimiser",
      "portfolio/coding/chords-search-engine",
      "portfolio/coding/dynamic-resource-optimiser",
      "portfolio/coding/meetup-maker",
      "portfolio/coding/note-together",
      "portfolio/coding/website-react"
    ]
  },
  "web-scraping": {
    "title": "Web Scraping",
    "importance": 8,
    "date": 2019,
    "proficiency": 10,
    "description": [
      {
        "title": "description",
        "text": "Web scraping is the automated extraction of data from websites, typically using specialised software or scripts, to collect and retrieve information from web pages, enabling tasks such as data aggregation, content extraction, and monitoring, for various purposes such as research, analysis, and data integration."
      },
      {
        "title": "background",
        "text": "Web scraping is one of my favourite things to do in the world of data science. Exploring different websites, finding patterns within data, and extracting and parsing the relevant information is quite satisfying to me. It gives a much better indication to me whether I did my job properly, as compared to machine learning and AI.\nMy first proper taste of Web Scraping came during my time in <</portfolio/experience/data-analytics>>National Service</>, where I had to extract out information pertaining to police stations and police posts, as well as community centres. This involved certain trickeries that were very fun to do.\nAnd while I do have some experience in <</portfolio/technology/selenium>>Selenium</>, I must say that most of my experience comes from BeautifulSoup and my own creation <</portfolio/coding/spiderman-scraper>>Spiderman Scraper</>, which is a custom web scraper I've built."
      }
    ],
    "related": [
      "portfolio/language/python",
      "portfolio/language/r",
      "portfolio/technology/gcp",
      "portfolio/technology/jupyter",
      "portfolio/technology/pandas",
      "portfolio/technology/selenium",
      "portfolio/skill/data-cleaning",
      "portfolio/skill/data-mining",
      "portfolio/skill/data-science",
      "portfolio/coding/chords-search-engine",
      "portfolio/coding/geospatial-extraction",
      "portfolio/coding/halal-recommender",
      "portfolio/coding/malls-of-singapore",
      "portfolio/coding/sentence-searcher",
      "portfolio/coding/spiderman-web-scraper",
      "portfolio/experience/data-analytics"
    ]
  }
}